# SEAL: Towards Safe Autonomous Driving via Skill-Enabled Adversary Learning for Closed-Loop Scenario Generation

[**Webpage**](https://cmubig.github.io/seal/) | [**Code**](https://github.com/cmubig/seal) | [**Paper**](https://arxiv.org/abs/2409.10320)



Verification and validation of autonomous driving (AD)
systems and components is of increasing importance, as such
technology increases in real-world prevalence.
Safety-critical scenario generation is a key approach to
robustify AD policies through closed-loop training.
However, existing approaches for scenario generation rely
on simplistic objectives, resulting in overly-aggressive or
non-reactive adversarial behaviors. To generate diverse
adversarial yet realistic scenarios, we propose SEAL, a
scenario perturbation approach which leverages learned
scoring functions and adversarial, human-like skills.
SEAL-perturbed scenarios are more realistic than SOTA
baselines, leading to improved ego task success across
real-world, in-distribution, and out-of-distribution
scenarios, of more than 20%.


## Instructions

To be included soon.

## Acknowledgement

This repository utilizes code from 
[CAT](https://github.com/metadriverse/cat), 
[ReSkill](https://github.com/krishanrana/reskill),
[MetaDrive](https://github.com/metadriverse/metadrive), and 
pretrained models from [DenseTNT](https://github.com/Tsinghua-MARS-Lab/DenseTNT) .

